---
abstract: We consider causality as a domain-general intuitive theory and ask
  whether this intuitive theory can be learned from cooccurrence of events. We
  begin by phrasing the causal Bayes nets theory of causality, and a range of
  alternatives, in a logical language for relational theories. This allows us to
  explore simultaneous inductive learning of an abstract theory of causality and
  a causal model for each of several causal systems. We find that the correct
  theory of causality can be learned relatively quickly, often becoming
  available before specific causal theories have been learnedâ€”an effect we term
  the "blessing of abstraction". We then explore the effect of providing a
  variety of auxiliary evidence, and find that a collection of simple "input
  analyzers" can help to bootstrap abstract knowledge. Together these results
  suggest that the most efficient route to causal knowledge may be to build in
  not an abstract notion of causality, but a powerful inductive learning
  mechanism and a variety of perceptual supports. While these results are purely
  computational, they have implications for cognitive development, which we
  explore in the conclusion.
draft: false
publication_types:
  - "2"
title: Learning a Theory of Causality
date: 2009-07-29T04:00:00.000Z
featured: false
authors:
  - Noah D Goodman
  - Tomer D Ullman
  - Joshua B Tenenbaum
tags:
  - Causality
  - Hierarchical Bayesian Modeling
  - Innateness
  - Bayesian Modeling
  - Theory Learning
categories: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
publication: "*Proceedings of the 31st Annual Conference of the Cognitive Science Society*"
publication_short: CogSci 2009
lastmod: 2020-08-28T02:32:59.000Z
doi: ""
---
