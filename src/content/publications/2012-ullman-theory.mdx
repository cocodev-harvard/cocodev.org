---
abstract: "We present an algorithmic model for the development of children's
  intuitive theories within a hierarchical Bayesian framework, where theories
  are described as sets of logical laws generated by a probabilistic
  context-free grammar. We contrast our approach with connectionist and other
  emergentist approaches to modeling cognitive development. While their
  subsymbolic representations provide a smooth error surface that supports
  efficient gradient-based learning, our symbolic representations are better
  suited to capturing children's intuitive theories but give rise to a harder
  learning problem, which can only be solved by exploratory search. Our
  algorithm attempts to discover the theory that best explains a set of observed
  data by performing stochastic search at two levels of abstraction: an outer
  loop in the space of theories and an inner loop in the space of explanations
  or models generated by each theory given a particular dataset. We show that
  this stochastic search is capable of learning appropriate theories in several
  everyday domains and discuss its dynamics in the context of empirical studies
  of children's learning."
draft: false
publication_types:
  - "2"
title: Theory learning as stochastic search in the language of thought
date: 2012-08-04T04:00:00.000Z
featured: false
authors:
  - Tomer D Ullman
  - Noah D Goodman
  - Joshua B Tenenbaum
tags:
  - Conceptual Change
  - Bayesian Models
  - Algorithms
  - Language of Thought
  - Intuitive Theories
categories: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
publication: "*Vol 27, Issue 4 of Cognitive Development*"
publication_short: Cognitive Development
lastmod: 2020-08-28T02:33:08.000Z
url_code: https://doi.org/10.1016/j.cogdev.2012.07.005
---
