---
abstract: When holding others morally responsible, we care about what they did
  and what they thought. Traditionally, research in moral psychology has relied
  on vignette studies, in which the protagonist’s actions and thoughts are
  explicitly communicated. Recent studies have begun to employ visual stimuli,
  and some have postulated a direct link from processing visual features to
  making moral judgments. We embrace the advent of visual stimuli in moral
  psychology, but believe that the connection between visual processing and
  moral judgments is mediated by an inference about what the observed action
  reveals about the agent’s mental states. We formalize moral judgments as
  computations over an intuitive theory of physics combined with an intuitive
  theory of mind. Knowing that mental states lead to action (e.g., the belief
  that someone is in harm’s way and the desire to help them stimulates a
  decision to shove them out of harm’s way), and that these actions are
  constrained by physics (the shove has to be forceful enough, aimed in the
  right direction, timed appropriately, etc.), allows an observer to make
  powerful inferences about moral responsibility. Two experiments show that this
  model captures moral judgments about physical scenes, both qualitatively and
  quantitatively.
draft: true
publication_types:
  - "1"
title: "Moral Dynamics: A Computational Model of Moral Judgment."
date: 2018-01-01
featured: false
authors:
  - Felix Sosa
  - Tomer Ullman
  - Samuel Gershman
  - Josh Tenenbaum
  - Tobias Gerstenberg
tags:
  - Moral Judgement
  - Effort
  - Intuitive Physics
  - Intuitive Psychology
categories: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
publication: Cognition
publication_short: Cognition
lastmod: 2020-08-28T02:34:50.000Z
url_code: https://github.com/flxsosa/MoralDynamics
---
